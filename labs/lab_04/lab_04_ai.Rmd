---
title: "lab_04_ai"
author: "Daniel Trielli"
date: "2024-09-26"
output: html_document
---

## Setup

Let's load the necessary libraries and, using your API key, setup your credentials:

```{r}
library(axolotr)
create_credentials(GROQ_API_KEY = "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")
```

See that "Please restart your R session for changes to take effect."? Go ahead and do that; you'll need to rerun the `library()` function for axolotr, and let's load tidyverse while we're at it.\

```{r}
library(axolotr)
library(tidyverse)
```

## Testing

Let's make sure that worked. We'll be using the [Llama 3.1 model released by Meta](https://ai.meta.com/blog/meta-llama-3-1/).

```{r}
groq_response <- axolotr::ask(
  prompt = "Give me a 100-word pitch for a new Lilo and Stitch sequel",
  model = "llama-3.1-8b-instant"
)

groq_response
```

Did that work?

## Q1. Turning unstructured information into data: let's take [this article](https://www.nytimes.com/2024/09/27/arts/maggie-smith-dead.html) about the death of Dame Maggie Smith and try to extract information from it. Your goal is to have Groq create a table with the films and TV shows mentioned in this news article, and extract the following information about them: title, year, role, director, co-stars, and awards. From the table that it created, answer this: is the information correct? Did all information come from the article text?

```{r}
#Loading article text
text = "Maggie Smith, one of the finest British stage and screen actors of her generation, whose award-winning roles ranged from a freethinking Scottish schoolteacher in /“The Prime of Miss Jean Brodie/” to the acid-tongued dowager countess on /“Downton Abbey,/” died on Friday in London. She was 89.

Her death, in a hospital, was announced by her family in a statement issued by a publicist. The statement gave no cause of death.

American moviegoers barely knew Ms. Smith (now Dame Maggie to her countrymen) when she starred in /“The Prime of Miss Jean Brodie/” (1969), about a 1930s girls’-school teacher who dared to have progressive social views — and a love life. Vincent Canby’s review in The New York Times described her performance as /“a staggering amalgam of counterpointed moods, switches in voice levels and obliquely stated emotions, all of which are precisely right./” It brought her the Academy Award for best actress.

She won a second Oscar, for best supporting actress, for /“California Suite/” (1978), based on Neil Simon’s stage comedy. Her character, a British actress attending the Oscars with her bisexual husband (Michael Caine), has a disappointing evening at the ceremony and a bittersweet night in bed.

In real life, prizes had begun coming Ms. Smith’s way in the 1950s, when at 20 she won her first Evening Standard Award. By the turn of the millennium, she had the two Oscars, two Tonys, two Golden Globes, half a dozen Baftas (British Academy of Film and Television Awards) and scores of nominations. Yet she could go almost anywhere unrecognized.

Until /“Downton Abbey./”

That series followed the Earl of Grantham (Hugh Bonneville), his mostly aristocratic family and his troubled household staff at their grand Jacobean mansion as the world around them, between 1912 and 1925, refused to stand still.

After its 2010 British premiere and its 2011 American debut, the show ran six seasons. Its breakout star, from the beginning, was Ms. Smith, playing Lord Grantham’s elderly and still stubbornly Victorian widowed mother, Violet Crawley, the dowager countess. She disapproved of electric lights, was unfamiliar with the word /“weekend/” and never met a person or situation she couldn’t ridicule with withering imperiousness. When her daughter-in-law considered sending a younger relative for a stay in New York, Lady Violet objected: /“Oh, I don’t think things are quite that desperate./”

Suddenly, in her mid-70s, Ms. Smith was a megastar.

/“It’s ridiculous. I’d led a perfectly normal life until ‘Downton Abbey,’ /” she told Mark Lawson at the B.F.I. and Radio Times Festival in 2017, adding later: /“Nobody knew who the hell I was./”

The closest Ms. Smith had come to such visibility was with the Harry Potter movies. She was Minerva McGonagall, the Hogwarts School’s stern but fearless transformation teacher, in seven of the eight films, from /“Harry Potter: The Sorceror’s Stone/” (2001) to /“Harry Potter: The Deathly Hallows Part 2/” (2011).

McGonagall, wearing high-necked Victorian-style gowns, a distinctive Scottish brooch, and upswept hair beneath a tall, black witch’s hat, was a striking onscreen presence. Yet Ms. Smith did not find herself constantly pursued in public, except by children.

/“A lot of very small people kind of used to say hello to me, and that was nice,/” she recalled on /“The Graham Norton Show/” in 2015. One boy carefully asked her, /“Were you really a cat?/”)"
```

```{r}
#Add code below to talk to Groq and display its response
smith_response <- axolotr::ask(
  prompt = paste("Given the following text, extract her mentioned films and television roles into a csv file with the following structure, including these as headers: title, year, role, director, co_stars, awards. And please Groq, do not talk to me, just generate the data.", text),
  model = "llama-3.1-8b-instant"
)

smith_response
smith_response_df <- read_csv(smith_response)
```

**Answer: In at least one iteration, the table generated by Groq seemed, to me, correct. However, fiddling with the code and running it multiple times produced some interesting variables. Sometimes, Groq seemed confused as to whether Downtown Abbey was a television program or a film, and would vacillate between displaying the year as the year of its conclusion, or the year it began running. Generally though, Groq seemed quite on the ball with it.**

------------------------------------------------------------------------

## Q2. Helping with code explanation: Your data journalism instructor has given you a block of code but you can't make sense of it. Ask Groq if it can explain what the code does with this UMD course. Is the answer correct?

```{r}
# Loading R code example
r_code_example = 'umd_courses |>
  filter(str_detect(title, "Climate") & seats > 0) |>
  group_by(department) |>
  summarize(classes = n()) |>
  arrange(desc(classes))'
```

```{r}
#Add code below to talk to Groq and display its response
umd_response <- axolotr::ask(
  prompt = paste("Groq, the programming logic in the given r_code_example doesn't make any sense to me. What is going on in this code?", r_code_example),
  model = "llama-3.1-8b-instant"
)

umd_response
```

**Answer: Groq seems correct here, although certain details don't seem totally on the mark. Groq tells me that the & boolean is a logical AND operator and only returns "TRUE" if two conditions are both met correctly. Well, that's not incorrect, but in practical terms, the code won't actually be doing that. It's instead going to filter out the "FALSE" observations from the "TRUE" observations. A tiny thing, but if I'm splitting hairs, it's something to point out.**

------------------------------------------------------------------------

## Q3. Helping with code debugging: paste the code block of an answer you had for a previous lab down here and ask Grok if that code is correct, based on the question in the lab. What do you think about its response?

```{r}
#Loading lab question
lab_question = 'Using case_when(), create a column in the Maryland expenses data called spending_location indicating whether each record indicated money spent in Maryland or outside Maryland, based on the address column of the \'maryland_expenses\' dataset. For records that are in Maryland, make the new column\'s value \"In-state\" and for the others, make it \"Out of state\". Then write code that shows the total amount of money spent in each category and describe the results. You can do this in one statement or break it up into two statements (saving the new column to your dataframe).'


#Paste the code block here, between the quotes. If your code has quotes or single quotes, you have to add a \ before each one so R doesn't break.

your_r_code_lab = "maryland_expenses <- maryland_expenses|>
  mutate(spending_location = case_when(
    str_detect(address, \" Maryland \") ~ \"In-state\",
    str_detect(address, \" California \") ~ \"Out of state\",
    str_detect(address, \" Washington \") ~ \"Out of state\",
    str_detect(address, \" Louisiana \") ~ \"Out of state\",
    str_detect(address, \" Florida \") ~ \"Out of state\",
    str_detect(address, \" North Carolina \") ~ \"Out of state\",
    str_detect(address, \" Massachusetts \") ~ \"Out of state\",
    str_detect(address, \" West Virginia \") ~ \"Out of state\",
    str_detect(address, \" Virginia \") ~ \"Out of state\",
    .default = NA
    )
  ) 
  
  spending_location_results <- maryland_expenses |>
  group_by(spending_location)|>
  summarise( 
    total_amount=sum(amount))"


```

```{r}
code_judgement <- axolotr::ask(
  prompt = paste("Groq, I've been attempting to answer the question in lab_question. I've written my code, given in your_r_code_lab, and I wanted to see if I used the right code to answer the question. What are your thoughts?", your_r_code_lab, lab_question),
  model = "llama-3.1-8b-instant"
)

code_judgement
```

**Answer: Groq hit me with some interesting notes here. Groq switched all of my out-of-state case_when's into one single line, all of which equate to "out-of-state." This feels very logical, but seems unintuitive – I can't imagine that massive string would look very good (or more importantly, lend itself very easily to editing) in a command terminal. More interestingly, however: Groq removed the spaces on the left and right hand sides of each state name, changing " Maryland " into "Maryland", and so on. This seems, instinctively, pointless: str_detect's whole function is finding strings regardless of exact specifications like that, and anyways, if I'm trying to find every instance of "Maryland" within the data set, why wouldn't I want to account for the possibility of spaces in the data – that is to say, why I wouldn't I want to account for human error during the data entry process? Of course, maybe Groq is right, and I'm just too illiterate in R to understand proper syntax.**

------------------------------------------------------------------------

## Q4. Brainstorming about strategies for data analysis and visualization: ask Groq to give you ideas about potential news stories from data analyses using [this data set](https://data.montgomerycountymd.gov/Public-Safety/Crash-Reporting-Incidents-Data/bhju-22kf/about_data). You're going to have to describe the dataset so that Groq can make some suggestions. What do you think of its response?

```{r}
#Add code below to talk to Groq and display its response
moco_dataset <- axolotr::ask(
  prompt = paste("Groq, I have a data set from Maryland's Montgomery County, detailing crash reports. There are thirty seven total columns in the table, with column names such as: report number, local case number, agency name, ACRS report type, crash date/time, hit/run, route type, lane direction, lane type, number of lanes, etc. What kind of a news story might I be able to generate from a data set like this? How might I find an interesting journalism story within the data?"),
  model = "llama-3.1-8b-instant"
)

moco_dataset
```

**Answer: I have to say, Groq's responses aren't terrible, but they're quite vague – things I feel that I could have come up with myself. This isn't to belittle Mr. Groq, he's doing the best he can with the relatively tiny information provided, but, for example, consider his response about high-risk intersections:**

```         
Here are some potential ideas:\n\n1. **Identifying High-Risk Intersections**: By analyzing the crash data, you can pinpoint intersections with the highest number of crashes, types of crashes (e.g., pedestrian vs. vehicle), and times of day when crashes are most likely to occur. This information can help inform local authorities and residents about areas that require increased safety measures.
```

Certainly helpful information who somebody who knows nothing about data research or journalistic practices, but beyond that, Groq's answer seems rather lacking in practical utility. I probably would have thought of that myself – okay, sure, look where the danger zones are, got it. Groq doesn't get into the specifics of how one might parse the data, i.e. methods of filtering, string detection, pivot tables, etc. Of course, I didn't tell Groq to do these things, so perhaps with a lot of retooling my initial prompt, the old man could get a little more specific.

------------------------------------------------------------------------

## Q5. Using AI to write news articles: ask Groq to write a 500-word news article about a car crash at the intersection between Knox Road and Regents Drive. What issues or problems do you see with the output?

```{r}
#Add code below to talk to Groq and display its response
ai_news_story <- axolotr::ask(
  prompt = paste("Groq, let's say that I need a 500-word news article about a crash at the intersection between Regents Drive and Knox Road in College Park, Maryland. Give it a hard news lead, explain who got in the crash and why, and tell me the current statuses of all involved parties. I would also like to know who's pressing charges, whether or not anybody has been killed, and the general timeframe of the crash. Please ensure that you follow Associated Press guidelines for grammar (street names, police officer titles, etc.) And please ensure that you pay due respect to the victims of the crash, if the circumstances are dire. Please give me the real name of any involved officials."),
  model = "llama-3.1-8b-instant"
)

ai_news_story

```

**Answer: Well, this is pretty hilarious – it feels like the exact kind of thing I'd type up for a JOUR620 assignment. The article itself seems pretty well composed, with paragraph breaks at appropriate moments and a proper lead/nut/graf/general inverted pyramid. Initially, Groq generated some nonsense names for the police chief, but after specifying that I wanted the real names of officials, Groq managed to grab them – both the name of the UMD police chief (David Mitchell) and Darryll Pines. There is, of course, the issue that it's all completely fabricated, and I imagine that Groq might struggle much more substantially with an actual, real-life event. There's also the rather substantial issue that Groq didn't pick up on: Regents Drive and Knox Road never actually actually intersect (forgive me for the colloquialism professor, but, lol). Groq was more than happy to churn out the story without bothering to check whether or not its most basic premise was actually true. This makes sense, of course – as an LLM Groq doesn't care about "true" or "untrue", but only the prompt given and the most likely response to said prompt. Still, pretty funny.**
